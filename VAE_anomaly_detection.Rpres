<style>
.footer {
    position: fixed; 
    top: 90%;
    text-align:right; 
    width:100%;
}

.banner {
    position: fixed; 
    top: 0%;
    text-align:right; 
    width:100%;
}

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  border: 0px;
}

.reveal table {
  border: 0px;
}

.reveal h1 {
  font-size: 1.6em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.small-code pre code {
  font-size: 1em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

</style>


Variational autoencoders for anomaly detection
========================================================
author: Sigrid Keydana, Trivadis
date: 2017/16/09
autosize: true
incremental:false
width: 1400
height: 900


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Variational autoencoders: Setting the scene</h1>


Welcome to the world of deep neural networks
========================================================

&nbsp;

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE,
                      cache = TRUE)
```

```{r}
library(ggplot2)
library(dplyr)
library(keras)
```

<figure>
    <img src='networkZooPoster_part.png' width='70%'/>
    <figcaption>Source: [1]</figcaption>
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


No magic involved: autoencoders
========================================================

&nbsp;

- neither a supervised nor an unsupervised, but a _self-supervised_ technique
- not conducive to learning interesting features / abstractions
- useful for applications such as image denoising and dimensionality reduction for visualization

<figure>
    <img src='autoencoder_schema.jpg' width='60%' />
    <figcaption>Source: [2]</figcaption>
</figure>


&nbsp;

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Anomalies
========================================================


&nbsp;

An outlier is...
_an observation which deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism_ [3]

&mdash;> we need a probabilistic approach

Enter: generative stochastic models
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Latent variable models
========================================================


&nbsp;

Maximize:

$P(X) = \int P(X|z;\theta) P(z) dz$
  
&nbsp;

<figure>
    <img src='vae_gm.png' width='40%' />
    <figcaption>Source: [4]</figcaption>
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Questions
========================================================

&nbsp;

- How do we get a mapping from easy-to-sample-from $z$'s to the empirical output ($X$)?

- How do we make sure our $z$'s are in the appropriate range to yield the $X$'s?


  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Variational autoencoder
========================================================

&nbsp;

- Sample from $P(Z) = \mathcal N(z|0,I)$

- Let the network learn the decoder: $P(X|z;\theta) = \mathcal N(X|f(z,\theta), \sigma^2 I)$

- Let the network learn the encoder: $Q(z|X)$


  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Variational autoencoder objective
========================================================


&nbsp;

Maximize the _variational lower bound_

$$E_{z \sim Q}[log P(X|z)] - \mathcal D[Q(z|X)||P(z)] $$

where the terms are

1) the reconstruction error

2) the Kullback-Leibler divergence between the approximate posterior and the prior for $z$
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


VAE in a nutshell
========================================================


&nbsp;

<figure>
    <img src='vae_doersch.png' width='80%' />
    <figcaption>Source: [4]</figcaption>
</figure>

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

How can we use this?
========================================================


&nbsp;

Generate stuff (e.g., images)
  
<figure>
    <img src='vae_generate.png' width='30%' />
    <figcaption>Source: [4]</figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

How can we use this for ANOMALY DETECTION?
========================================================

&nbsp;

- VAE models the distribution, not the values

- anomalies are seen as coming from a _different process / distribution_, so...

- can diagnose as anomalies those cases that have _high reconstruction error / low reconstruction probability_ [5]


  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Let's see this in practice!
========================================================


&nbsp;

- MNIST, what else ;-)

- fraud detection

- network intrusion detection
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Technology employed
========================================================

&nbsp;

- <a href="http://keras.io">Keras</a>, used from R, via the <a href="https://keras.rstudio.com/">bindings provided by Rstudio</a>:
    - used for all models

- <a href="https://deeplearning4j.org">DL4J</a>: 
    - for reconstruction-probability based outliers in MNIST

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Variational-autoencoding MNIST</h1>


Ubiquitous MNIST
========================================================

&nbsp;

MNIST handwritten digits database

<figure>
    <img src='mnist.jpg' width='40%' />
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



The encoder
========================================================
class:small-code

&nbsp;

```{r, eval=FALSE, echo=TRUE}
 # input layer
x <- layer_input(batch_shape = c(batch_size, original_dim))   
# hidden intermediate, lower-res
h <- layer_dense(x, intermediate_dim, activation = "relu") 
# latent var 1, 2-dim (mainly for plotting!): mean
z_mean <- layer_dense(h, latent_dim)    
# latent var 2, 2-dim: variance
z_log_var <- layer_dense(h, latent_dim)                            

sampling <- function(arg){
  z_mean <- arg[,0:1]
  z_log_var <- arg[,2:3]
  
  epsilon <- K$random_normal(
    shape = c(batch_size, latent_dim), 
    mean=0.,
    stddev=epsilon_std
  )
  z_mean + K$exp(z_log_var/2)*epsilon
}

# latent vars are sampled: nondeterministic!
z <- layer_concatenate(list(z_mean, z_log_var)) %>%               
  layer_lambda(sampling)

```

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


The decoder
========================================================
class:small-code

&nbsp;

```{r, eval=FALSE, echo=TRUE}
# the latent layer from above
z <- layer_concatenate(list(z_mean, z_log_var)) %>%                            
  layer_lambda(sampling)

# hidden intermediate, higher-res
decoder_h <- layer_dense(units = intermediate_dim, activation = "relu") 
# decoder for the mean, high-res again
decoder_mean <- layer_dense(units = original_dim, activation = "sigmoid")      

h_decoded <- decoder_h(z)
x_decoded_mean <- decoder_mean(h_decoded)

```

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


The model
========================================================
class:small-code

&nbsp;

```{r, eval=FALSE, echo=TRUE}
# the complete model, from input to decoded output
vae <- keras_model(x, x_decoded_mean)                                          

# cross-entropy: the reconstruction part of the loss function
xent_loss <- function(target, reconstruction) {
  as.double(original_dim) * loss_binary_crossentropy(target, reconstruction)   
}

# Kullback-Leibler divergence: the regularization part of the loss function
kl_loss <- function(target, reconstruction) {
  -0.5*K$mean(1 + z_log_var - K$square(z_mean) - K$exp(z_log_var), axis = -1L)
}

vae_loss <- function(x, x_decoded_mean){
  xent_loss <- (original_dim/1.0)*loss_binary_crossentropy(x, x_decoded_mean)
  kl_loss <- -0.5*K$mean(1 + z_log_var - K$square(z_mean) - K$exp(z_log_var), axis = -1L)
  xent_loss + kl_loss
}

# compile the model with (hopefully) adequate optimizer and learning rate
vae %>% compile(optimizer = optimizer_rmsprop(lr = learning_rate), loss = vae_loss, metrics = c(xent_loss, kl_loss))


```

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



MNIST latent space
========================================================

&nbsp;


<table>
<tr>
<td><img src='mnist_latent.png' /></td>
<td><img src='mnist_generated.png' /></td>
</tr>
</table>

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Best and worst reconstructions
========================================================

&nbsp;

using reconstruction probability

<figure>
    <img src='mnist_best_worst.png' width='50%' />
</figure>


  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

So which are the anomalies?
========================================================

&nbsp;

- have to define cut-off points
- as with other machine learning /statistics-based algorithms
- so is this a problem?
- the more urgent question really is...
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

How well does this work with real-world datasets?
========================================================

&nbsp;

- MNIST is 28*28 pixels, grayscale ==> super homogeneous data!
- best supervised learning error rate as of today (test set): 0.23% ==> super simple!
    
How about real datasets with different types of variables of different scale?
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Real-world example: fraud detection</h1>


Fraudulent Transactions [6]
========================================================

&nbsp;

- data "from an undisclosed source", anonymized
- transactions reported by salespeople
    - salesman id
    - product id
    - quantity sold
    - total value of sale
    - fraud yes/no/unknown
- total transactions 401,146 - of these, 385,414 unknown!
    
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Before we start tweaking model parameters...
========================================================

&nbsp;

How to best preprocess the _data_?

- product ids will have to be one-hot-encoded (but won't be able to use them all to avoid overly sparse matrix)
- quantity and total value should both be kept (not reduced to unit price!) because each of them may be informative _alone_
- however, we need all data to be on similar scale to be able to pick an adequate loss function
- thus, quantity and total value have to be normalized
- nonetheless, we have a mix of 0/1 and continuous data - let's see how this goes...
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Parameterizing the model for fraud detection
========================================================

&nbsp;

- in theory, binary crossentropy should work fine for data between 0 and 1
- in practice, mean squared error worked better
- using MSE, also had to change activation of the output (decoded mean) layer to linear
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Training procedure
========================================================

&nbsp;

- not evident how to proceed with the unlabeled ("unknown") data (= 96% of whole dataset!)
- decision: train on "unknown" set, use labeled data (fraud or non-fraud) for testing
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Fraud latent space:
========================================================

&nbsp;

<figure><img src='fraud_latent.png' />
</figure>
  
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Scores on test set
========================================================

&nbsp;

Reconstruction error (MSE, in this case):

- final MSE on training set: 3.50
- MSE on _fraud_ test set: 3.57
- MSE on _non-fraud_ test set: 3.49

Problem: small sample sizes (non-fraud: 6013, fraud: 180)


  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Real-world example: network intrusion detection</h1>


UNSW-NB15 intrusion detection dataset [7,8]
========================================================

&nbsp;

- synthetic dataset
- 9 types of attack: fuzzers, analysis, backdoors, DoS, exploits, generic, reconnaissance, shellcode, worms
- 49 features created from raw network traffic captured with tcpdump

<figur><img src="unsw.png" width="40%"/></figure>
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Again - what shall we do with the data?
========================================================

&nbsp;

- tried: one-hot encoding _protocol_, _service_ and _state_ categorical variables
- tried: binning and one-hot-encoding continuous variables
- tried: different ways of normalizing continuous variables
- in the end, what worked best was getting rid of the categorical variables and scaling all others

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


How should we parameterize the model?
========================================================
class:small-code

&nbsp;

- tried different loss functions appropriate for normally distributed data, MSE worked best
- also used batch normalization and $l2$ regularization for all hidden layers, e.g.

```{r, echo=TRUE, eval=FALSE}
h <- layer_dense(x, intermediate_dim) 
if(use_batch_normalization) h <- h %>% layer_batch_normalization() 
h <- h %>% layer_activation("relu") %>% layer_activity_regularization(l1=l1, l2=l2)
```

  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Training procedure
========================================================

&nbsp;

- dataset already comes with a training set and a test set
- use all non-attack records from the training set (= 37,000) for training - that's not _too_ much given the complexity of the data
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Network intrusions latent space:
========================================================

&nbsp;

<table>
<tr>
<td><img src='unsw_latent.png' /></td><td><img src='unsw_latent_zoom.png' /></td>
</tr>
</table>
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Scores on test set
========================================================

&nbsp;

Reconstruction error (MSE):

<table>
<tr><td><em>type</em></td><td><em>number of cases</em></td><td><em>MSE</em></td></tr>
<tr><td>normal (no attack)</td><td>56,000</td><td>40.4</td></tr>
<tr><td>analysis</td><td>2,000</td><td>81.1</td></tr>
<tr><td>DoS</td><td>12,264</td><td>55.3</td></tr>
<tr><td>exploits</td><td>33,393</td><td>50.4</td></tr>
<tr><td>fuzzers</td><td>18,184</td><td>37.8</td></tr>
<tr><td>generic</td><td>40,000</td><td>48.8</td></tr>
<tr><td>reconnaissance</td><td>10,491</td><td>20.5</td></tr>
<tr><td>shellcode</td><td>1,133</td><td>19.3</td></tr>
<tr><td>worms</td><td>130</td><td>38.6</td></tr>
</table>



  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Conclusion
========================================================

&nbsp;

- not sure we're ready for a conclusion yet...
- definitely too much preprocessing involved, given we want to use DL for automation
- conceptually, VAE is a very pleasing fit for the task because of its inherent probabilistic nature
- in practice, this may need further experimentation, e.g., use embeddings on categorical variables
- desirable: follow up model performance (e.g., the intrusion detection model) together with a _domain expert_


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Questions?
========================================================

&nbsp;

Thanks for your attention!

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Sources
========================================================
class:smalltext

&nbsp;

[1] Asimov Institute, <a href='http://www.asimovinstitute.org/neural-network-zoo/'>The Neural Network Zoo.</a>

[2] Keras blog, <a href='https://blog.keras.io/building-autoencoders-in-keras.html'>Building autoencoders in Keras.</a>

[3] Hawkins, D. (1980), Identification of outliers. Chapman and Hall, London.

[4] Doersch, C.,<a href="https://arxiv.org/pdf/1606.05908.pdf">Tutorial on Variational Autoencoders.</a>  

[5] An, J. & Cho, S.,<a href="http://dm.snu.ac.kr/static/docs/TR/SNUDM-TR-2015-03.pdf">Variational Autoencoder based Anomaly Detection using Reconstruction Probability</a>

[6] Torgo, L. (2017), Data Mining with R, 2nd ed.

[7] Moustafa, Nour, and Jill Slay. "UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)."Military Communications and Information Systems Conference (MilCIS), 2015. IEEE, 2015.

[8] Moustafa, Nour, and Jill Slay. "The evaluation of Network Anomaly Detection Systems: Statistical analysis of the UNSW-NB15 data set and the comparison with the KDD99 data set." Information Security Journal: A Global Perspective (2016): 1-14.
